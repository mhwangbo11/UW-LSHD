---
title: "Model Results (STATs)"
author: "Min Hwangbo"
date: "December 5, 2018"
output: 
  html_document:
    theme: paper
    highlight: pygments
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: true
    smooth_scroll: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=TRUE}
# Using these packages in this lecture
library("broom") #output list and grabs commonly used dataframes
library("ggeffects") #pllotting marginal effects (expected values over the range of other variables)
library("pander") #regression tables
library("sjPlot") #sjPlot
library("tidyverse")
```

```{r}
ex_dat <- data.frame(num1 = rnorm(200, 1, 2), 
                     fac1 = sample(c(1, 2, 3), 200, TRUE),
                     num2 = rnorm(200, 0, 3),
                     fac2 = sample(c(1, 2))) %>%
  mutate(yn = num1*0.5 + fac1*1.1 + num2*0.7 + fac2-1.5  + rnorm(200, 0, 2)) %>% 
  mutate(yb = as.numeric(yn > mean(yn))) %>%
  mutate(fac1 = factor(fac1, labels=c("A", "B", "C")),
         fac2 = factor(fac2, labels=c("Yes", "No")))
#framing data
```

#`broom`
```{r}
#tidy(): dataframe summaries
#augment()
#glance()
```

##`broom::tidy()`
```{r}
lm_1 <- lm(yn ~ num1 + fac1, data = ex_dat)
glm_1 <- glm(yb ~ num1 + fac1, data = ex_dat, family=binomial(link="logit"))
lm_1 %>% tidy()
glm_1 %>% tidy()
```

##`broom::glance()`
```{r}
glance(lm_1)
```

##`broom::augment()`
```{r}
augment(lm_1) %>% head()
```

##The Power of broom
```{r}
#do() repeats whatever is inside it once for each level of the variable(s) in group_by() then puts them together as a data frame.
ex_dat %>% group_by(fac1) %>% do(tidy(lm(yn ~  num1 + fac2 + num2, data = ex_dat)))
#subgroup or national data sets overview
```

#`ggeffects`
* Vocabs!

* When we set variables to certain values, we refer to them as counterfactual values or just counterfactuals.

* For example, if we know nothing about a new observation, our prediction for that estimate is often based on assuming every variable is at its mean.

* Sometimes, however, we might have very specific questions which require setting (possibly many) combinations of variables to particular values and making an estimate or prediction.

* Providing specific estimates, conditional on values of covariates, is a nice way to summarize results, particularly for models with unintuitive parameters (e.g. logit models).

##`ggeffects`packets
* Tidyframe
* Ranges of predictive values
* `ggpredicts()` -  Computes predicted values for the outcome variable (Y) at margins of specific variables (X1 or X2).
* `plot.ggeffects()` - A plot method for ggeffects objects (like `ggredict()` output)

##`ggpredict()`
* One predictor using the terms argument
```{R}
lm_1_est<- ggpredict(lm_1, terms = "num1")
lm_1_est
```

##`plot()` for `ggpredict()`
```{r}
plot(lm_1_est)
```

## Grouping with `ggpredict()`
```{r}
glm(yb ~ num1 + fac1 + num2 + fac2, data = ex_dat, family=binomial(link = "logit")) %>%
  ggpredict(terms = c("num1", "fac1")) %>% plot()
```

## Faceting with `ggpredict()`
```{r}
glm(yb ~ num1 + fac1 + num2 + fac2, data = ex_dat, family = binomial(link = "logit")) %>%
  ggpredict(terms = c("num1", "fac1")) %>% plot(facet=TRUE)
```

## Counterfactual Values using `terms=`
```{r}
glm(yb ~ num1 + fac1 + num2 + fac2, data=ex_dat, family=binomial(link="logit")) %>%
ggpredict(terms = c("num1 [-1,0,1]", "fac1 [A,B]")) %>% plot(facet=TRUE)
```

## Representative Values using `[meansd]` or `[minmax]`
```{r}
glm(yb ~ num1 + fac1 + num2 + fac2, data = ex_dat, family = binomial(link = "logit")) %>%
  ggpredict(terms = c("num1 [meansd]", "num2 [minmax]")) %>% plot(facet=TRUE)
#exploratory visual of a model
```

## Dot plots with `ggpredict()`
```{r}
lm(yn ~ fac1 + fac2, data = ex_dat) %>% 
  ggpredict(terms=c("fac1", "fac2")) %>% plot()
```

## Notes on `ggeffects()`
There is a lot more to the `ggeffects` package that you can see in the package vignette and the github repository. This includes, but is not limited to:

* Predicted values for polynomial and interaction terms

* Getting predictions from models from dozens of other packages

* Sending `ggeffects` objects to `ggplot2` to freely modify plots

# Advanced Examples 
* Read this: https://onlinelibrary.wiley.com/doi/full/10.1111/cico.12346
* Interactions going on
** Target Race x Caller Race
** Crime Type x Caller Race
** Target Race x Neigbhorhood Type
** Crime Type x Neighborhood Type
```{r, eval=FALSE}  
load("data/any_arrest_data.RData")
mod_arrest <- glm(arrest ~ white_comp_wit_vict*black_arr_susp + 
                  crime_type*white_comp_wit_vict + caller_type + 
                  arr_susp_subj_count + comp_wit_vict_count +
                  black_arr_susp*neighb_type + crime_type*neighb_type + 
                  serious_rate + pbl + pot + dis + year,
                  family = binomial(link = "logit"),
                  data = any_arrest_data)
```

## Bootstrapping
* Page 27

## Simulating Coefficients
```{r, eval=FALSE}
sim_params <- MASS::mvrnorm(n = 10000, 
                            mu = coef(mod_arrest),
                            Sigma = vcov(mod_arrest))
sim_params[1:6, 1:4]
```

## Counterfactual Values
```{r, eval=FALSE}
x_values <- colMeans(model.matrix(mod_arrest)) # vars at mean
n_scen   <- (2*2*2*3) # Number of scenarios
x_frame  <- setNames(data.frame(matrix(x_values, nrow=n_scen, 
                                       ncol=length(x_values), 
                                       byrow=T)), names(x_values))
cf_vals  <- arrangements::permutations(c(0,1), k=5, replace=T)
cf_vals  <- cf_vals[cf_vals[,4]+cf_vals[,5]!=2 ,] # Remove impossible vals
colnames(cf_vals) <- c("white_comp_wit_vict1", "black_arr_susp1", 
                       "crime_typeNuisance", "neighb_typeBlackDisadv",
                       "neighb_typeChanging")
x_frame[colnames(cf_vals)] <- cf_vals # assign to countefactual df
```

### What do we have?
```{r, eval=FALSE}
glimpse(x_frame)
x_frame <- x_frame %>%
 mutate(
  `white_comp_wit_vict1:black_arr_susp1`      = white_comp_wit_vict1*black_arr_susp1,
  `white_comp_wit_vict1:crime_typeNuisance`   = white_comp_wit_vict1*crime_typeNuisance,
  `black_arr_susp1:neighb_typeBlackDisadv`    = black_arr_susp1*neighb_typeBlackDisadv,
  `black_arr_susp1:neighb_typeChanging`       = black_arr_susp1*neighb_typeChanging,
  `crime_typeNuisance:neighb_typeBlackDisadv` = crime_typeNuisance*neighb_typeBlackDisadv,
  `crime_typeNuisance:neighb_typeChanging`    = crime_typeNuisance*neighb_typeChanging,
  `black_arr_susp1:neighb_typeBlackDisadv`    = black_arr_susp1*neighb_typeBlackDisadv,
  `black_arr_susp1:neighb_typeChanging`       = black_arr_susp1*neighb_typeChanging)
#Let's fix this
glimpse(x_frame)
#Fixed
```

### Estimates!
```{r, eval=FALSE}
sims_logodds <- sim_params %*% t(as.matrix(x_frame))  
sims_logodds[1:6, 1:6]
dim(sims_logodds)
```

### Probabilities

```{r, eval=FALSE}
sims_prob    <- exp(sims_logodds) / (1 + exp(sims_logodds))
sims_prob[1:6, 1:6]
extract_pe_ci <- function(x){
  vals <- c(mean(x), quantile(x, probs=c(.025, .975)))
  names(vals) <- c("PE", "LB", "UB")
  return(vals)
}
```

### Prep for Plotting
```{r, eval=FALSE}
estimated_pes <- as.data.frame( t(apply(sims_prob, 2, extract_pe_ci)))
estimated_pes$`Reporter`     <- ifelse(cf_vals[,1]==1, "Any White", "All Black")
estimated_pes$`Target`       <- ifelse(cf_vals[,2]==1, "Any Black", "All White")
estimated_pes$`Crime Type`   <- ifelse(cf_vals[,3]==1, "Nuisance Crime", "Serious Crime")
estimated_pes$`Neighborhood` <- case_when(
  cf_vals[,4]==1 ~ "Disadvantaged",
  cf_vals[,5]==1 ~ "Changing",
  TRUE ~ "Stable White")
```

### Clean data
```{r, eval=FALSE}
estimated_pes %>% mutate_if(is.numeric, round, digits=3) # round for display
```

### Plotting Codes!
```{r, eval=FALSE}
ggplot(estimated_pes, aes(x = Target, y = PE, group = Reporter)) + 
  facet_grid(`Crime Type` ~ Neighborhood) +
  geom_errorbar(aes(ymin = LB, ymax = UB), 
                position = position_dodge(width = .4), 
                size = 0.75, width = 0.15) +
  geom_point(shape = 21, aes(fill = Reporter),
             position = position_dodge(width = .4), 
             size = 2) + 
  scale_fill_manual("Reporter", values=c("Any White" = "white", 
                                         "All Black" = "black")) +
  ggtitle("Figure 3. Probability of Arrest", 
      subtitle = "by Reporter and Target Race, Neighborhood and Crime Type") +
  xlab("Race of Target") + ylab("Estimated Probability") + 
  theme_bw() + theme(legend.position = c(0.86,0.15),
                     legend.background = element_rect(color = 1))
```
# `sjPlot`
* html table

## `sjPlot`Tables
```{r}
model_1 <- lm(mpg ~ wt, data = mtcars)
tab_model(model_1)
#Multi model tables
model_2 <- lm(mpg ~ hp + wt, data = mtcars)
model_3 <- lm(mpg ~ hp + wt + factor(am), data = mtcars)
tab_model(model_1, model_2, model_3)
```

# `corrplot`
```{r}
library(corrplot)
corrplot(
  cor(mtcars),
  addCoef.col = "white",
  addCoefasPercent=T,
  type="upper", 
  order="AOE")
```

# Wrap Up
## What did I learn?

* How to get data into R from a variety of formats
* How to do "data custodian" work to manipulate and clean data
* How to make pretty visualizations
* How to automate with loops and functions
* How to combine text, calculations, plots, and tables into dynamic R Markdown reports
* How to acquire and work with spatial data
* How to visualize a model result

## What's next?

* Stats inference 

Functions for hypothesis testing, hierarchical/mixed effect models, machine learning, survey design, etc. are straightforward   to use... once data are clean

* Practice

Replicate analyses you've done in Excel, SPSS, or Stata

* Project management

Using version control (git) in RStudio

Interactive Shiny web apps

Write your own functions and put them in a package